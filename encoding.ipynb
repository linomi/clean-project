{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.projection = layers.Conv2D(\n",
    "            filters=self.embed_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            strides=self.patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(input_shape[1],-1, self.embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulationEmbedding(layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens,embed_dim= input_shape\n",
    "        self.position_embedding = layers.Embedding(input_dim=num_tokens, output_dim= embed_dim)\n",
    "        self.speed_embedding = layers.Embedding(input_dim = num_tokens, output_dim= embed_dim)\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "    def call(self, encoded_tokens,runing_speed):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_speed = self.speed_embedding(runing_speed)\n",
    "        x = encoded_tokens + encoded_speed\n",
    "        encoded_tokens = encoded_tokens + encoded_speed + encoded_positions\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 5 15 10], shape=(3,), dtype=int32) encoded speed\n",
      "tf.Tensor([ 5 15 10], shape=(3,), dtype=int32) encoded_tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = ModulationEmbedding()(np.ones((5,15,10)),np.ones((5,15)))\n",
    "#m = Model(in_model,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
